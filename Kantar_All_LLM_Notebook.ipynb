{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143108c4",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Kantar All‚ÄëLLM Notebook (Azure OpenAI, Few‚ÄëShots + Glossary)\n",
    "\n",
    "This notebook implements an **LLM‚Äëonly** pipeline to extract:\n",
    "- **sector**, **categoria**, **marca**, **size**, **unit**  \n",
    "from noisy product text using **Azure OpenAI** with:\n",
    "- **Augmented few‚Äëshots:** auto‚Äësampled from your train data **+** hand‚Äëpicked tricky examples\n",
    "- **Soft label glossary:** suggest allowed values to the model (not hard‚Äëenforced)\n",
    "- **JSON Schema enforced** outputs\n",
    "- Optional **self‚Äëconsistency** (vote/median over multiple generations)\n",
    "- **Weighted F1** evaluation vs. test ground truth (if present)\n",
    "\n",
    "> ‚öôÔ∏è You‚Äôll need Azure env vars set on your machine:  \n",
    "`AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_DEPLOYMENT`, and `AZURE_OPENAI_API_VERSION=2024-12-01-preview`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270bd0d",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup\n",
    "Install dependencies once (uncomment if needed):\n",
    "```bash\n",
    "# !pip install -U openai==1.* pandas numpy scikit-learn nbformat\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, json, unicodedata, random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce015cb",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load data & utilities\n",
    "- Normalize column names\n",
    "- Pick text column (e.g., `clean_description` in train, `ocr_text` in test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811782dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_col(name: str) -> str:\n",
    "    s2 = ''.join(c for c in unicodedata.normalize('NFD', name) if unicodedata.category(c) != 'Mn')\n",
    "    return re.sub(r'\\s+', '_', s2.strip().lower())\n",
    "\n",
    "def load_and_normalize(train_path: str, test_path: str):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "    train.columns = [normalize_col(c) for c in train.columns]\n",
    "    test.columns  = [normalize_col(c) for c in test.columns]\n",
    "    return train, test\n",
    "\n",
    "def pick_text_col(df: pd.DataFrame) -> str:\n",
    "    candidates = [\n",
    "        \"ocr_text\",\"ocr\",\"text\",\"descripcion\",\"description\",\"clean_description\",\n",
    "        \"product_description\",\"full_text\",\"title\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    str_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "    assert str_cols, \"No string-like columns found for text.\"\n",
    "    return max(str_cols, key=lambda c: df[c].fillna(\"\").astype(str).str.len().mean())\n",
    "\n",
    "def map_target_columns(train: pd.DataFrame):\n",
    "    mapping = {}\n",
    "    candidates = {\n",
    "        \"sector\":    [\"sector\"],\n",
    "        \"categoria\": [\"categoria\",\"category\",\"categor√≠a\"],\n",
    "        \"marca\":     [\"marca\",\"brand\"],\n",
    "    }\n",
    "    for tgt, aliases in candidates.items():\n",
    "        for a in aliases:\n",
    "            a = normalize_col(a)\n",
    "            if a in train.columns:\n",
    "                mapping[tgt] = a\n",
    "                break\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cf363",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Few‚Äëshots (auto + hand‚Äëpicked) & soft label glossary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIZE_RE = re.compile(\n",
    "    r\"(?P<qty>\\d+(?:[\\.,]\\d+)?)\\s*(?P<unit>ml|l|lt|litros?|ltrs?|cc|cl|g|gr|gramos?|kg|kgs?|un|uds?|u|pack|pz|pcs?)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def _maybe_size_unit(text: str):\n",
    "    if not isinstance(text, str): return None, None\n",
    "    m = SIZE_RE.search(text)\n",
    "    if not m: return None, None\n",
    "    q = m.group(\"qty\").replace(\",\", \".\")\n",
    "    try: qv = float(q)\n",
    "    except: qv = None\n",
    "    unit = m.group(\"unit\").lower()\n",
    "    unit_map = {\"lt\":\"l\",\"ltrs\":\"l\",\"litro\":\"l\",\"litros\":\"l\",\"gr\":\"g\",\"gramo\":\"g\",\"gramos\":\"g\",\"kgs\":\"kg\",\"uds\":\"un\",\"pz\":\"pcs\",\"u\":\"un\"}\n",
    "    return qv, unit_map.get(unit, unit)\n",
    "\n",
    "def build_auto_fewshots(train: pd.DataFrame, text_col: str, label_cols: List[str],\n",
    "                        per_label: int = 2, max_examples: int = 24, seed: int = 42):\n",
    "    rng = random.Random(seed)\n",
    "    examples = []\n",
    "    pool = train.copy()\n",
    "    pool[\"_has_size\"] = pool[text_col].astype(str).str.contains(SIZE_RE)\n",
    "    pool = pd.concat([pool[pool[\"_has_size\"]], pool[~pool[\"_has_size\"]]]).drop(columns=[\"_has_size\"])\n",
    "\n",
    "    primary = None\n",
    "    for cand in [\"categoria\",\"category\",\"sector\",\"marca\",\"brand\"]:\n",
    "        c = normalize_col(cand)\n",
    "        if c in label_cols:\n",
    "            primary = c\n",
    "            break\n",
    "\n",
    "    if primary:\n",
    "        vc = pool[primary].value_counts()\n",
    "        classes = list(vc.index)\n",
    "        rng.shuffle(classes)\n",
    "        for cls in classes:\n",
    "            rows = pool[pool[primary]==cls]\n",
    "            if len(rows)==0: continue\n",
    "            rows = rows.sample(min(per_label, len(rows)), random_state=seed)\n",
    "            for _, r in rows.iterrows():\n",
    "                ex = {\"text\": str(r[text_col])}\n",
    "                for lc in label_cols:\n",
    "                    if lc in r and pd.notna(r[lc]): ex[lc] = str(r[lc])\n",
    "                q,u = _maybe_size_unit(r[text_col])\n",
    "                if q is not None: ex[\"size\"] = q\n",
    "                if u is not None: ex[\"unit\"] = u\n",
    "                examples.append(ex)\n",
    "                if len(examples) >= max_examples:\n",
    "                    return examples\n",
    "        return examples[:max_examples]\n",
    "    else:\n",
    "        for _, r in pool.sample(min(max_examples, len(pool)), random_state=seed).iterrows():\n",
    "            ex = {\"text\": str(r[text_col])}\n",
    "            for lc in label_cols:\n",
    "                if lc in r and pd.notna(r[lc]): ex[lc] = str(r[lc])\n",
    "            q,u = _maybe_size_unit(r[text_col])\n",
    "            if q is not None: ex[\"size\"] = q\n",
    "            if u is not None: ex[\"unit\"] = u\n",
    "            examples.append(ex)\n",
    "        return examples\n",
    "\n",
    "def validate_handpicked_examples(handpicked: List[Dict]):\n",
    "    cleaned = []\n",
    "    for ex in handpicked or []:\n",
    "        if not isinstance(ex, dict): continue\n",
    "        if \"text\" not in ex or not str(ex[\"text\"]).strip(): continue\n",
    "        out = {\"text\": str(ex[\"text\"]).strip()}\n",
    "        for k in [\"sector\",\"categoria\",\"category\",\"marca\",\"brand\",\"size\",\"unit\"]:\n",
    "            if k in ex and ex[k] is not None:\n",
    "                out[k] = ex[k]\n",
    "        cleaned.append(out)\n",
    "    return cleaned\n",
    "\n",
    "def merge_fewshots(auto_shots: List[Dict], handpicked: List[Dict], max_total: int = 40):\n",
    "    merged = (handpicked or []) + (auto_shots or [])\n",
    "    seen, deduped = set(), []\n",
    "    for ex in merged:\n",
    "        t = ex.get(\"text\", \"\").strip()\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            deduped.append(ex)\n",
    "        if len(deduped) >= max_total:\n",
    "            break\n",
    "    return deduped\n",
    "\n",
    "def glossary_block(glossary: Optional[Dict[str, List[str]]]):\n",
    "    if not glossary: \n",
    "        return \"\"\n",
    "    lines = []\n",
    "    for k, vals in glossary.items():\n",
    "        if not vals: continue\n",
    "        preview = \", \".join(vals[:30]) + (\"\" if len(vals)<=30 else \", ...\")\n",
    "        lines.append(f\"- {k}: prefer one of [{preview}] when applicable; if none fits, output a best guess.\")\n",
    "    if not lines:\n",
    "        return \"\"\n",
    "    return (\n",
    "        \"\\\\nLabel glossary (soft guidance; not hard rules):\\\\n\"\n",
    "        + \"\\\\n\".join(lines)\n",
    "        + \"\\\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ec02f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Build messages (system with soft glossary + few‚Äëshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_messages(fewshots: List[Dict], text: str, label_glossary: Optional[Dict[str, List[str]]] = None):\n",
    "    system = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You normalize retail product descriptions from noisy OCR.\\n\"\n",
    "            \"Extract keys: sector (string), categoria (string), marca (string), size (number or null), unit (string or null).\\n\"\n",
    "            \"Guidelines:\\n\"\n",
    "            \"- Keep strings concise and canonical.\\n\"\n",
    "            \"- If a value cannot be determined, use null.\\n\"\n",
    "            \"- For multi-brand mentions, choose the primary product brand; avoid retailer or sub-brands unless clearly primary.\\n\"\n",
    "            \"- For packs, if the text implies multiples (e.g., '6x330ml'), prioritize the single-item size (330) and unit ('ml').\\n\"\n",
    "            \"- Normalize common units like ml,l,g,kg,un,pcs.\\n\"\n",
    "            + glossary_block(label_glossary)\n",
    "        )\n",
    "    }\n",
    "    shots = []\n",
    "    for ex in fewshots:\n",
    "        shots.append({\"role\": \"user\", \"content\": ex[\"text\"]})\n",
    "        out = {\n",
    "            \"sector\": ex.get(\"sector\"),\n",
    "            \"categoria\": ex.get(\"categoria\") or ex.get(\"category\"),\n",
    "            \"marca\": ex.get(\"marca\") or ex.get(\"brand\"),\n",
    "            \"size\": ex.get(\"size\"),\n",
    "            \"unit\": ex.get(\"unit\"),\n",
    "        }\n",
    "        shots.append({\"role\": \"assistant\", \"content\": json.dumps(out, ensure_ascii=False)})\n",
    "    return [system] + shots + [{\"role\":\"user\",\"content\": text}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910fe36",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Azure OpenAI client + JSON Schema enforcement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_azure_client():\n",
    "    from openai import AzureOpenAI\n",
    "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    return AzureOpenAI(api_version=api_version, azure_endpoint=endpoint, api_key=key)\n",
    "\n",
    "def _json_schema():\n",
    "    return {\n",
    "        \"name\": \"KantarExtraction\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"properties\": {\n",
    "                \"sector\":    {\"type\": [\"string\",\"null\"]},\n",
    "                \"categoria\": {\"type\": [\"string\",\"null\"]},\n",
    "                \"marca\":     {\"type\": [\"string\",\"null\"]},\n",
    "                \"size\":      {\"type\": [\"number\",\"null\"]},\n",
    "                \"unit\":      {\"type\": [\"string\",\"null\"]}\n",
    "            },\n",
    "            \"required\": [\"sector\",\"categoria\",\"marca\",\"size\",\"unit\"]\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "\n",
    "def call_llm_jsonschema(client, deployment: str, messages: List[Dict],\n",
    "                        temperature: float = 0.2, max_tokens: int = 600):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=1.0,\n",
    "        response_format={\"type\":\"json_schema\",\"json_schema\":_json_schema()},\n",
    "    )\n",
    "    content = resp.choices[0].message.content\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except Exception:\n",
    "        return {\"sector\": None, \"categoria\": None, \"marca\": None, \"size\": None, \"unit\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17622123",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Self‚Äëconsistency aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _majority_vote_str(candidates: List[Optional[str]]) -> Optional[str]:\n",
    "    c = [x.strip() for x in candidates if isinstance(x, str) and x.strip()!=\"\"]\n",
    "    if not c: return None\n",
    "    keys = [x.lower() for x in c]\n",
    "    vc = pd.Series(keys).value_counts()\n",
    "    top_key = vc.index[0]\n",
    "    for orig in c:\n",
    "        if orig.lower() == top_key:\n",
    "            return orig\n",
    "    return c[0]\n",
    "\n",
    "def _median_number(candidates: List[Optional[float]]) -> Optional[float]:\n",
    "    vals = [float(x) for x in candidates if isinstance(x,(int,float))]\n",
    "    if not vals: return None\n",
    "    return float(np.median(vals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb52c5f",
   "metadata": {},
   "source": [
    "\n",
    "## 6) End‚Äëto‚Äëend All‚ÄëLLM runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898133f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_f1(y_true: pd.Series, y_pred: List) -> Optional[float]:\n",
    "    from sklearn.metrics import f1_score\n",
    "    mask = y_true.notna()\n",
    "    if mask.sum() == 0:\n",
    "        return None\n",
    "    return float(\n",
    "        f1_score(\n",
    "            y_true[mask].astype(str),\n",
    "            pd.Series(y_pred)[mask].astype(str),\n",
    "            average=\"weighted\",\n",
    "            zero_division=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "def score_predictions(test: pd.DataFrame, targets: Dict[str, str], preds: Dict[str, List]):\n",
    "    scores = {}\n",
    "    for tgt, col in targets.items():\n",
    "        pred_col = f\"pred_{tgt}\"\n",
    "        if col in test.columns and pred_col in preds:\n",
    "            scores[tgt] = weighted_f1(test[col], preds[pred_col])\n",
    "    return scores\n",
    "\n",
    "def save_outputs(test: pd.DataFrame, preds: Dict[str, List], out_csv: str,\n",
    "                 metrics_json: str, scores: Dict[str, Optional[float]]):\n",
    "    out = test.copy()\n",
    "    for k, v in preds.items():\n",
    "        out[k] = v\n",
    "    Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    with open(metrics_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({k: (None if v is None else round(v, 4)) for k,v in scores.items()},\n",
    "                  f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def run_all_llm(train: pd.DataFrame, test: pd.DataFrame, out_csv: str, metrics_json: str,\n",
    "                handpicked_examples: Optional[List[Dict]] = None,\n",
    "                label_glossary: Optional[Dict[str, List[str]]] = None,\n",
    "                max_fewshots: int = 40, per_label: int = 2,\n",
    "                n_candidates: int = 1, temperature: float = 0.2,\n",
    "                max_tokens: int = 600, seed: int = 42):\n",
    "    train_text = pick_text_col(train)\n",
    "    test_text  = pick_text_col(test)\n",
    "    targets    = map_target_columns(train)\n",
    "\n",
    "    auto_shots = build_auto_fewshots(train, train_text, list(targets.values()),\n",
    "                                     per_label=per_label, max_examples=max_fewshots, seed=seed)\n",
    "    handpicked = validate_handpicked_examples(handpicked_examples or [])\n",
    "    fewshots   = merge_fewshots(auto_shots, handpicked, max_total=max_fewshots)\n",
    "\n",
    "    client = get_azure_client()\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "    if not deployment:\n",
    "        raise RuntimeError(\"Set AZURE_OPENAI_DEPLOYMENT to your chat model deployment name.\")\n",
    "\n",
    "    pred_sector, pred_categoria, pred_marca, pred_size, pred_unit = [], [], [], [], []\n",
    "    texts = test[test_text].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    for t in texts:\n",
    "        messages = build_messages(fewshots, t, label_glossary=label_glossary)\n",
    "        cand_objs = []\n",
    "        for _ in range(max(1, n_candidates)):\n",
    "            js = call_llm_jsonschema(client, deployment, messages, temperature=temperature, max_tokens=max_tokens)\n",
    "            cand_objs.append(js)\n",
    "\n",
    "        sector    = _majority_vote_str([c.get(\"sector\") for c in cand_objs])\n",
    "        categoria = _majority_vote_str([c.get(\"categoria\") for c in cand_objs])\n",
    "        marca     = _majority_vote_str([c.get(\"marca\") for c in cand_objs])\n",
    "        size      = _median_number([c.get(\"size\") for c in cand_objs])\n",
    "        unit      = _majority_vote_str([c.get(\"unit\") for c in cand_objs])\n",
    "\n",
    "        pred_sector.append(sector)\n",
    "        pred_categoria.append(categoria)\n",
    "        pred_marca.append(marca)\n",
    "        pred_size.append(size)\n",
    "        pred_unit.append(unit)\n",
    "\n",
    "    preds = {\n",
    "        \"pred_sector\": pred_sector,\n",
    "        \"pred_categoria\": pred_categoria,\n",
    "        \"pred_marca\": pred_marca,\n",
    "        \"pred_size\": pred_size,\n",
    "        \"pred_unit\": pred_unit,\n",
    "    }\n",
    "\n",
    "    scores = score_predictions(test, targets, preds)\n",
    "    save_outputs(test, preds, out_csv, metrics_json, scores)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d11b5",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Example usage\n",
    "Fill in your file paths and (optionally) handpicked tricky examples and a soft glossary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Example usage (uncomment to run on your machine)\n",
    "# train, test = load_and_normalize('Kantar_train.csv', 'Kantar_test.csv')\n",
    "#\n",
    "# tricky = [\n",
    "#   {\"text\": \"Coca-Cola Zero 6x330ml Lata\", \"sector\":\"Bebidas\", \"categoria\":\"Gaseosas\", \"marca\":\"Coca-Cola\", \"size\":330, \"unit\":\"ml\"},\n",
    "#   {\"text\": \"Leche Deslactosada Alpina 1L\", \"sector\":\"L√°cteos\", \"categoria\":\"Leche\", \"marca\":\"Alpina\", \"size\":1, \"unit\":\"l\"},\n",
    "#   {\"text\": \"Chocolate para Taza Luker 250 g Pack x2\", \"sector\":\"Alimentos\", \"categoria\":\"Chocolate\", \"marca\":\"Luker\", \"size\":250, \"unit\":\"g\"},\n",
    "#   {\"text\": \"Caf√© Colcaf√© Tradicional Frasco 170g\", \"sector\":\"Alimentos\", \"categoria\":\"Caf√©\", \"marca\":\"Colcaf√©\", \"size\":170, \"unit\":\"g\"},\n",
    "#   {\"text\": \"Yogur Griego Natural Danone 4x125g\", \"sector\":\"L√°cteos\", \"categoria\":\"Yogur\", \"marca\":\"Danone\", \"size\":125, \"unit\":\"g\"},\n",
    "# ]\n",
    "#\n",
    "# glossary = {\n",
    "#   \"sector\":    [\"Alimentos\",\"Bebidas\",\"L√°cteos\",\"Higiene\",\"Aseo\",\"Snacks\"],\n",
    "#   \"categoria\": [\"Caf√©\",\"Chocolate\",\"Gaseosas\",\"Leche\",\"Yogur\",\"Galletas\",\"Cereales\"],\n",
    "#   \"marca\":     [\"Coca-Cola\",\"Pepsi\",\"Nestl√©\",\"Luker\",\"Colcaf√©\",\"Alpina\",\"Danone\",\"Bimbo\"]\n",
    "# }\n",
    "#\n",
    "# scores = run_all_llm(\n",
    "#   train=train,\n",
    "#   test=test,\n",
    "#   out_csv='predictions.csv',\n",
    "#   metrics_json='metrics.json',\n",
    "#   handpicked_examples=tricky,\n",
    "#   label_glossary=glossary,\n",
    "#   max_fewshots=40,\n",
    "#   per_label=2,\n",
    "#   n_candidates=3,\n",
    "#   temperature=0.2,\n",
    "#   max_tokens=600\n",
    "# )\n",
    "# print('Weighted F1:', scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BASIC AZURE OPENAI LLM TEST ---\n",
    "# Checks if your Azure setup, key, and deployment are working.\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import os, json\n",
    "\n",
    "# 1Ô∏è‚É£ Set your Azure environment variables before running:\n",
    "# export AZURE_OPENAI_ENDPOINT=\"https://<your-endpoint>.openai.azure.com/\"\n",
    "# export AZURE_OPENAI_API_KEY=\"<your-key>\"\n",
    "# export AZURE_OPENAI_DEPLOYMENT=\"<your-deployment-name>\"\n",
    "# export AZURE_OPENAI_API_VERSION=\"2024-12-01-preview\"\n",
    "\n",
    "# 2Ô∏è‚É£ Initialize the client\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\"),\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Create a simple structured prompt\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a product classification assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract the product sector, category, brand, size, and unit from this text:\\n\\n'Caf√© Colcaf√© Tradicional Frasco 170g'\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 4Ô∏è‚É£ Call the model with structured JSON schema response\n",
    "response = client.chat.completions.create(\n",
    "    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"ProductExtraction\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sector\": {\"type\": \"string\"},\n",
    "                    \"categoria\": {\"type\": \"string\"},\n",
    "                    \"marca\": {\"type\": \"string\"},\n",
    "                    \"size\": {\"type\": \"number\"},\n",
    "                    \"unit\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"sector\", \"categoria\", \"marca\", \"size\", \"unit\"],\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    "    temperature=0.2,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Print parsed structured JSON output\n",
    "print(\"Raw content:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "try:\n",
    "    parsed = json.loads(response.choices[0].message.content)\n",
    "    print(\"\\n‚úÖ Parsed JSON:\")\n",
    "    print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
    "except Exception as e:\n",
    "    print(\"\\n‚ö†Ô∏è Could not parse response:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
